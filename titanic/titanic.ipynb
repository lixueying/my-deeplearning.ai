{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass                                               Name  \\\n",
      "0            892       3                                   Kelly, Mr. James   \n",
      "1            893       3                   Wilkes, Mrs. James (Ellen Needs)   \n",
      "2            894       2                          Myles, Mr. Thomas Francis   \n",
      "3            895       3                                   Wirz, Mr. Albert   \n",
      "4            896       3       Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
      "5            897       3                         Svensson, Mr. Johan Cervin   \n",
      "6            898       3                               Connolly, Miss. Kate   \n",
      "7            899       2                       Caldwell, Mr. Albert Francis   \n",
      "8            900       3          Abrahim, Mrs. Joseph (Sophie Halaut Easu)   \n",
      "9            901       3                            Davies, Mr. John Samuel   \n",
      "10           902       3                                   Ilieff, Mr. Ylio   \n",
      "11           903       1                         Jones, Mr. Charles Cresson   \n",
      "12           904       1      Snyder, Mrs. John Pillsbury (Nelle Stevenson)   \n",
      "13           905       2                               Howard, Mr. Benjamin   \n",
      "14           906       1  Chaffee, Mrs. Herbert Fuller (Carrie Constance...   \n",
      "15           907       2      del Carlo, Mrs. Sebastiano (Argenia Genovesi)   \n",
      "16           908       2                                  Keane, Mr. Daniel   \n",
      "17           909       3                                  Assaf, Mr. Gerios   \n",
      "18           910       3                       Ilmakangas, Miss. Ida Livija   \n",
      "19           911       3              Assaf Khalil, Mrs. Mariana (Miriam\")\"   \n",
      "20           912       1                             Rothschild, Mr. Martin   \n",
      "21           913       3                          Olsen, Master. Artur Karl   \n",
      "22           914       1               Flegenheim, Mrs. Alfred (Antoinette)   \n",
      "23           915       1                    Williams, Mr. Richard Norris II   \n",
      "24           916       1    Ryerson, Mrs. Arthur Larned (Emily Maria Borie)   \n",
      "25           917       3                            Robins, Mr. Alexander A   \n",
      "26           918       1                       Ostby, Miss. Helene Ragnhild   \n",
      "27           919       3                                  Daher, Mr. Shedid   \n",
      "28           920       1                            Brady, Mr. John Bertram   \n",
      "29           921       3                                  Samaan, Mr. Elias   \n",
      "..           ...     ...                                                ...   \n",
      "388         1280       3                               Canavan, Mr. Patrick   \n",
      "389         1281       3                        Palsson, Master. Paul Folke   \n",
      "390         1282       1                         Payne, Mr. Vivian Ponsonby   \n",
      "391         1283       1     Lines, Mrs. Ernest H (Elizabeth Lindsey James)   \n",
      "392         1284       3                      Abbott, Master. Eugene Joseph   \n",
      "393         1285       2                               Gilbert, Mr. William   \n",
      "394         1286       3                           Kink-Heilmann, Mr. Anton   \n",
      "395         1287       1     Smith, Mrs. Lucien Philip (Mary Eloise Hughes)   \n",
      "396         1288       3                               Colbert, Mr. Patrick   \n",
      "397         1289       1  Frolicher-Stehli, Mrs. Maxmillian (Margaretha ...   \n",
      "398         1290       3                     Larsson-Rondberg, Mr. Edvard A   \n",
      "399         1291       3                           Conlon, Mr. Thomas Henry   \n",
      "400         1292       1                            Bonnell, Miss. Caroline   \n",
      "401         1293       2                                    Gale, Mr. Harry   \n",
      "402         1294       1                     Gibson, Miss. Dorothy Winifred   \n",
      "403         1295       1                             Carrau, Mr. Jose Pedro   \n",
      "404         1296       1                       Frauenthal, Mr. Isaac Gerald   \n",
      "405         1297       2       Nourney, Mr. Alfred (Baron von Drachstedt\")\"   \n",
      "406         1298       2                          Ware, Mr. William Jeffery   \n",
      "407         1299       1                         Widener, Mr. George Dunton   \n",
      "408         1300       3                    Riordan, Miss. Johanna Hannah\"\"   \n",
      "409         1301       3                          Peacock, Miss. Treasteall   \n",
      "410         1302       3                             Naughton, Miss. Hannah   \n",
      "411         1303       1    Minahan, Mrs. William Edward (Lillian E Thorpe)   \n",
      "412         1304       3                     Henriksson, Miss. Jenny Lovisa   \n",
      "413         1305       3                                 Spector, Mr. Woolf   \n",
      "414         1306       1                       Oliva y Ocana, Dona. Fermina   \n",
      "415         1307       3                       Saether, Mr. Simon Sivertsen   \n",
      "416         1308       3                                Ware, Mr. Frederick   \n",
      "417         1309       3                           Peter, Master. Michael J   \n",
      "\n",
      "        Sex   Age  SibSp  Parch              Ticket      Fare  \\\n",
      "0      male  34.5      0      0              330911    7.8292   \n",
      "1    female  47.0      1      0              363272    7.0000   \n",
      "2      male  62.0      0      0              240276    9.6875   \n",
      "3      male  27.0      0      0              315154    8.6625   \n",
      "4    female  22.0      1      1             3101298   12.2875   \n",
      "5      male  14.0      0      0                7538    9.2250   \n",
      "6    female  30.0      0      0              330972    7.6292   \n",
      "7      male  26.0      1      1              248738   29.0000   \n",
      "8    female  18.0      0      0                2657    7.2292   \n",
      "9      male  21.0      2      0           A/4 48871   24.1500   \n",
      "10     male   NaN      0      0              349220    7.8958   \n",
      "11     male  46.0      0      0                 694   26.0000   \n",
      "12   female  23.0      1      0               21228   82.2667   \n",
      "13     male  63.0      1      0               24065   26.0000   \n",
      "14   female  47.0      1      0         W.E.P. 5734   61.1750   \n",
      "15   female  24.0      1      0       SC/PARIS 2167   27.7208   \n",
      "16     male  35.0      0      0              233734   12.3500   \n",
      "17     male  21.0      0      0                2692    7.2250   \n",
      "18   female  27.0      1      0    STON/O2. 3101270    7.9250   \n",
      "19   female  45.0      0      0                2696    7.2250   \n",
      "20     male  55.0      1      0            PC 17603   59.4000   \n",
      "21     male   9.0      0      1             C 17368    3.1708   \n",
      "22   female   NaN      0      0            PC 17598   31.6833   \n",
      "23     male  21.0      0      1            PC 17597   61.3792   \n",
      "24   female  48.0      1      3            PC 17608  262.3750   \n",
      "25     male  50.0      1      0           A/5. 3337   14.5000   \n",
      "26   female  22.0      0      1              113509   61.9792   \n",
      "27     male  22.5      0      0                2698    7.2250   \n",
      "28     male  41.0      0      0              113054   30.5000   \n",
      "29     male   NaN      2      0                2662   21.6792   \n",
      "..      ...   ...    ...    ...                 ...       ...   \n",
      "388    male  21.0      0      0              364858    7.7500   \n",
      "389    male   6.0      3      1              349909   21.0750   \n",
      "390    male  23.0      0      0               12749   93.5000   \n",
      "391  female  51.0      0      1            PC 17592   39.4000   \n",
      "392    male  13.0      0      2           C.A. 2673   20.2500   \n",
      "393    male  47.0      0      0          C.A. 30769   10.5000   \n",
      "394    male  29.0      3      1              315153   22.0250   \n",
      "395  female  18.0      1      0               13695   60.0000   \n",
      "396    male  24.0      0      0              371109    7.2500   \n",
      "397  female  48.0      1      1               13567   79.2000   \n",
      "398    male  22.0      0      0              347065    7.7750   \n",
      "399    male  31.0      0      0               21332    7.7333   \n",
      "400  female  30.0      0      0               36928  164.8667   \n",
      "401    male  38.0      1      0               28664   21.0000   \n",
      "402  female  22.0      0      1              112378   59.4000   \n",
      "403    male  17.0      0      0              113059   47.1000   \n",
      "404    male  43.0      1      0               17765   27.7208   \n",
      "405    male  20.0      0      0       SC/PARIS 2166   13.8625   \n",
      "406    male  23.0      1      0               28666   10.5000   \n",
      "407    male  50.0      1      1              113503  211.5000   \n",
      "408  female   NaN      0      0              334915    7.7208   \n",
      "409  female   3.0      1      1  SOTON/O.Q. 3101315   13.7750   \n",
      "410  female   NaN      0      0              365237    7.7500   \n",
      "411  female  37.0      1      0               19928   90.0000   \n",
      "412  female  28.0      0      0              347086    7.7750   \n",
      "413    male   NaN      0      0           A.5. 3236    8.0500   \n",
      "414  female  39.0      0      0            PC 17758  108.9000   \n",
      "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   \n",
      "416    male   NaN      0      0              359309    8.0500   \n",
      "417    male   NaN      1      1                2668   22.3583   \n",
      "\n",
      "               Cabin Embarked  \n",
      "0                NaN        Q  \n",
      "1                NaN        S  \n",
      "2                NaN        Q  \n",
      "3                NaN        S  \n",
      "4                NaN        S  \n",
      "5                NaN        S  \n",
      "6                NaN        Q  \n",
      "7                NaN        S  \n",
      "8                NaN        C  \n",
      "9                NaN        S  \n",
      "10               NaN        S  \n",
      "11               NaN        S  \n",
      "12               B45        S  \n",
      "13               NaN        S  \n",
      "14               E31        S  \n",
      "15               NaN        C  \n",
      "16               NaN        Q  \n",
      "17               NaN        C  \n",
      "18               NaN        S  \n",
      "19               NaN        C  \n",
      "20               NaN        C  \n",
      "21               NaN        S  \n",
      "22               NaN        S  \n",
      "23               NaN        C  \n",
      "24   B57 B59 B63 B66        C  \n",
      "25               NaN        S  \n",
      "26               B36        C  \n",
      "27               NaN        C  \n",
      "28               A21        S  \n",
      "29               NaN        C  \n",
      "..               ...      ...  \n",
      "388              NaN        Q  \n",
      "389              NaN        S  \n",
      "390              B24        S  \n",
      "391              D28        S  \n",
      "392              NaN        S  \n",
      "393              NaN        S  \n",
      "394              NaN        S  \n",
      "395              C31        S  \n",
      "396              NaN        Q  \n",
      "397              B41        C  \n",
      "398              NaN        S  \n",
      "399              NaN        Q  \n",
      "400               C7        S  \n",
      "401              NaN        S  \n",
      "402              NaN        C  \n",
      "403              NaN        S  \n",
      "404              D40        C  \n",
      "405              D38        C  \n",
      "406              NaN        S  \n",
      "407              C80        C  \n",
      "408              NaN        Q  \n",
      "409              NaN        S  \n",
      "410              NaN        Q  \n",
      "411              C78        Q  \n",
      "412              NaN        S  \n",
      "413              NaN        S  \n",
      "414             C105        C  \n",
      "415              NaN        S  \n",
      "416              NaN        S  \n",
      "417              NaN        C  \n",
      "\n",
      "[418 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# print(train_data.columns[:12])\n",
    "# print(train_data)\n",
    "print(test_data)\n",
    "# train_data.describe()\n",
    "# test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 分析数据\n",
    "# PassengerId => 乘客ID\n",
    "# Pclass => 乘客等级(1/2/3等舱位)\n",
    "# Name => 乘客姓名\n",
    "# Sex => 性别\n",
    "# Age => 年龄\n",
    "# SibSp => 堂兄弟/妹个数\n",
    "# Parch => 父母与小孩个数\n",
    "# Ticket => 船票信息\n",
    "# Fare => 票价\n",
    "# Cabin => 客舱\n",
    "# Embarked => 登船港口\n",
    "train_data.info()\n",
    "# data = train_data['Fare'].fillna(train_data['Fare'].median())\n",
    "# print(raw_data['Fare'])\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pclass => 乘客等级(1/2/3等舱位)\n",
    "# print (train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "\n",
    "# print (train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())\n",
    "# # 将sibsp,parch合并成一个特征，主要是看是否是一个人\n",
    "# train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1 \n",
    "# print (train_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())\n",
    "# train_data['IsAlone'] = 0\n",
    "# train_data.loc[train_data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# print (train_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n",
    "# # 终点站这个特征有C，Q，S三个值，这个特征有缺失值，将其填充为S。同样需要进行映射为0,1,2。\n",
    "# train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "# print (train_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n",
    "# # 船票票价这个特征是一个连续型数据，我们对其进行处理平分为四等分，后面分别映射为0，1，2，3。\n",
    "# # raw_data['Fare'] = raw_data['Fare'].fillna(raw_data['Fare'].median())\n",
    "# train_data['CategoricalFare'] = pd.qcut(train_data['Fare'], 4)\n",
    "# print (train_data[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())\n",
    "# # 年龄这个特征同样也是连续型数据，而且缺失值比较多，我们可以将缺失值当做一个类别进行处理，其他的年龄可以等分为五种类别，在后续的数据清理中处理，这里就总共有六种类别\n",
    "# age_null_count = train_data['Age'].isnull().sum()\n",
    "# averge_age = train_data['Age'].sum() / (891-age_null_count)\n",
    "# # 将为空的年龄填成平均年龄\n",
    "# train_data['Age'] = train_data['Age'].fillna(averge_age)\n",
    "# # print(raw_data['Age'])\n",
    "# # print(age_not_null_sum / (891-age_null_count))\n",
    "# # print(raw_data['Survived'][raw_data['Age'].isnull()])\n",
    "# train_data['CategoricalAge'] = pd.cut(train_data['Age'], 5)\n",
    "# print (train_data[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())\n",
    "\n",
    "def processing_data(dataset):\n",
    "# 处理数据\n",
    "#     性别映射为0，1\n",
    "    dataset['Sex'] = dataset['Sex'].replace(['male', 'female'],[0, 1])\n",
    "    \n",
    "    # 将SibSp和Parch两个合并为一个特征，家庭大小，并同时扩展为是否独自一人的特征\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "#     终点站，缺失值补充为S，有三种类型 \n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # 票价，0，1，2，3四种\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # 年龄，缺失值为类别5\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "    dataset.loc[ dataset['Age'].isnull(), 'Age']                       = 5\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "    #replace missing value with U0\n",
    "    dataset['Cabin'] = dataset.Cabin.fillna('U0') # dataset.Cabin[dataset.Cabin.isnull()]='U0'\n",
    "    \n",
    "    drop_elements = ['PassengerId', 'Name', 'Ticket', 'SibSp','Parch']\n",
    "    dataset = dataset.drop(drop_elements, axis = 1)\n",
    "    \n",
    "    model_data = dataset[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'FamilySize', 'IsAlone']]\n",
    "#     pre_treatment_data = model_data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "    data = model_data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "\n",
    "    return data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(processing_data(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6eecb51e10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6eecb89748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画图\n",
    "# train_data.groupby(['Sex','Survived'])['Survived'].count()\n",
    "train_data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar()\n",
    "# train_data.groupby(['Pclass','Survived'])['Pclass'].count()\n",
    "# train_data[['Pclass','Survived']].groupby(['Pclass']).mean().plot.bar()\n",
    "\n",
    "bins = [0, 12, 18, 65, 100]\n",
    "train_data['Age_group'] = pd.cut(train_data['Age'], bins)\n",
    "train_data.groupby('Age_group')['Survived'].mean().plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector \n",
    "    n_y -- scalar, number of classes \n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "    X = tf.placeholder(shape=[n_x, None], dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=[n_y, None], dtype=tf.float32)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.Variable(tf.random_normal([4, 7]), name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([4, 1]), name='b1')\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([10, 4]), name='W2')\n",
    "    b2 = tf.Variable(tf.random_normal([10, 1]), name='b2')\n",
    "\n",
    "    W3 = tf.Variable(tf.random_normal([1, 10]), name='W3')\n",
    "    b3 = tf.Variable(tf.random_normal([1, 1]), name='b3')\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                            # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "#     logits = tf.transpose(Z3)\n",
    "#     labels = tf.transpose(Y)\n",
    "    \n",
    "#     print(logits)\n",
    "#     print(labels)\n",
    "\n",
    "#     print(Z3.shape)\n",
    "#     print(Y.shape)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z3, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "#     print('X shape is: ', X_train.shape)\n",
    "#     print('Y shape is: ', Y_train.shape)\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "#     n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []       # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X = tf.placeholder(dtype = np.float32, shape = [n_x, None])\n",
    "    Y = tf.placeholder(dtype = np.float32, shape = [1, None])  \n",
    "#     print(X.shape[1])\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "#     print(parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            print(minibatch_size)\n",
    "            print(m)\n",
    "            print(m // minibatch_size)\n",
    "            num_minibatches = m // minibatch_size # number of minibatches of size minibatch_size in the train set\n",
    "\n",
    "        \n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        # print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "        print('Optimization Finished!')\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        \n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train.T}))\n",
    "        print (\"-------------Done----------------------\")\n",
    "\n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preTreatmentData(train_data)\n",
    "# parameters = model(train_data, train_label)\n",
    "# data = processing_data(train_data)\n",
    "# train_label = train_data['Survived']\n",
    "\n",
    "# print(data.shape)\n",
    "# print(train_label.shape)\n",
    "# model(np.transpose(data.values), train_label.values.reshape((1, -1)))\n",
    "# train_data.info()\n",
    "# print(preTreatmentData(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "None\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "# test_set = processing_data(test_data)\n",
    "# test_label = test_data['Survived']\n",
    "print(test_data.info())\n",
    "print(test_data.shape)\n",
    "# model(np.transpose(test_set.values), test_label.values.reshape((1, -1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
