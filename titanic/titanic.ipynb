{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "5              6         0       3   \n",
      "6              7         0       1   \n",
      "7              8         0       3   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "12            13         0       3   \n",
      "13            14         0       3   \n",
      "14            15         0       3   \n",
      "15            16         1       2   \n",
      "16            17         0       3   \n",
      "17            18         1       2   \n",
      "18            19         0       3   \n",
      "19            20         1       3   \n",
      "20            21         0       2   \n",
      "21            22         1       2   \n",
      "22            23         1       3   \n",
      "23            24         1       1   \n",
      "24            25         0       3   \n",
      "25            26         1       3   \n",
      "26            27         0       3   \n",
      "27            28         0       1   \n",
      "28            29         1       3   \n",
      "29            30         0       3   \n",
      "..           ...       ...     ...   \n",
      "861          862         0       2   \n",
      "862          863         1       1   \n",
      "863          864         0       3   \n",
      "864          865         0       2   \n",
      "865          866         1       2   \n",
      "866          867         1       2   \n",
      "867          868         0       1   \n",
      "868          869         0       3   \n",
      "869          870         1       3   \n",
      "870          871         0       3   \n",
      "871          872         1       1   \n",
      "872          873         0       1   \n",
      "873          874         0       3   \n",
      "874          875         1       2   \n",
      "875          876         1       3   \n",
      "876          877         0       3   \n",
      "877          878         0       3   \n",
      "878          879         0       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "881          882         0       3   \n",
      "882          883         0       3   \n",
      "883          884         0       2   \n",
      "884          885         0       3   \n",
      "885          886         0       3   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                     Moran, Mr. James    male   NaN      0   \n",
      "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
      "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
      "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
      "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
      "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
      "16                                Rice, Master. Eugene    male   2.0      4   \n",
      "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
      "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
      "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
      "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
      "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
      "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
      "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
      "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
      "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
      "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
      "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
      "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
      "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
      "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
      "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
      "864                             Gill, Mr. John William    male  24.0      0   \n",
      "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
      "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
      "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
      "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
      "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
      "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
      "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
      "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
      "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
      "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
      "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
      "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
      "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
      "881                                 Markun, Mr. Johann    male  33.0      0   \n",
      "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
      "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
      "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
      "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket      Fare        Cabin Embarked  \n",
      "0        0         A/5 21171    7.2500          NaN        S  \n",
      "1        0          PC 17599   71.2833          C85        C  \n",
      "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
      "3        0            113803   53.1000         C123        S  \n",
      "4        0            373450    8.0500          NaN        S  \n",
      "5        0            330877    8.4583          NaN        Q  \n",
      "6        0             17463   51.8625          E46        S  \n",
      "7        1            349909   21.0750          NaN        S  \n",
      "8        2            347742   11.1333          NaN        S  \n",
      "9        0            237736   30.0708          NaN        C  \n",
      "10       1           PP 9549   16.7000           G6        S  \n",
      "11       0            113783   26.5500         C103        S  \n",
      "12       0         A/5. 2151    8.0500          NaN        S  \n",
      "13       5            347082   31.2750          NaN        S  \n",
      "14       0            350406    7.8542          NaN        S  \n",
      "15       0            248706   16.0000          NaN        S  \n",
      "16       1            382652   29.1250          NaN        Q  \n",
      "17       0            244373   13.0000          NaN        S  \n",
      "18       0            345763   18.0000          NaN        S  \n",
      "19       0              2649    7.2250          NaN        C  \n",
      "20       0            239865   26.0000          NaN        S  \n",
      "21       0            248698   13.0000          D56        S  \n",
      "22       0            330923    8.0292          NaN        Q  \n",
      "23       0            113788   35.5000           A6        S  \n",
      "24       1            349909   21.0750          NaN        S  \n",
      "25       5            347077   31.3875          NaN        S  \n",
      "26       0              2631    7.2250          NaN        C  \n",
      "27       2             19950  263.0000  C23 C25 C27        S  \n",
      "28       0            330959    7.8792          NaN        Q  \n",
      "29       0            349216    7.8958          NaN        S  \n",
      "..     ...               ...       ...          ...      ...  \n",
      "861      0             28134   11.5000          NaN        S  \n",
      "862      0             17466   25.9292          D17        S  \n",
      "863      2          CA. 2343   69.5500          NaN        S  \n",
      "864      0            233866   13.0000          NaN        S  \n",
      "865      0            236852   13.0000          NaN        S  \n",
      "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
      "867      0          PC 17590   50.4958          A24        S  \n",
      "868      0            345777    9.5000          NaN        S  \n",
      "869      1            347742   11.1333          NaN        S  \n",
      "870      0            349248    7.8958          NaN        S  \n",
      "871      1             11751   52.5542          D35        S  \n",
      "872      0               695    5.0000  B51 B53 B55        S  \n",
      "873      0            345765    9.0000          NaN        S  \n",
      "874      0         P/PP 3381   24.0000          NaN        C  \n",
      "875      0              2667    7.2250          NaN        C  \n",
      "876      0              7534    9.8458          NaN        S  \n",
      "877      0            349212    7.8958          NaN        S  \n",
      "878      0            349217    7.8958          NaN        S  \n",
      "879      1             11767   83.1583          C50        C  \n",
      "880      1            230433   26.0000          NaN        S  \n",
      "881      0            349257    7.8958          NaN        S  \n",
      "882      0              7552   10.5167          NaN        S  \n",
      "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
      "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
      "885      5            382652   29.1250          NaN        Q  \n",
      "886      0            211536   13.0000          NaN        S  \n",
      "887      0            112053   30.0000          B42        S  \n",
      "888      2        W./C. 6607   23.4500          NaN        S  \n",
      "889      0            111369   30.0000         C148        C  \n",
      "890      0            370376    7.7500          NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# download data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(train_data.columns[:12])\n",
    "print(train_data)\n",
    "# train_data.describe()\n",
    "# test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# 分析数据\n",
    "# PassengerId => 乘客ID\n",
    "# Pclass => 乘客等级(1/2/3等舱位)\n",
    "# Name => 乘客姓名\n",
    "# Sex => 性别\n",
    "# Age => 年龄\n",
    "# SibSp => 堂兄弟/妹个数\n",
    "# Parch => 父母与小孩个数\n",
    "# Ticket => 船票信息\n",
    "# Fare => 票价\n",
    "# Cabin => 客舱\n",
    "# Embarked => 登船港口\n",
    "train_data.info()\n",
    "# data = train_data['Fare'].fillna(train_data['Fare'].median())\n",
    "# print(raw_data['Fare'])\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pclass => 乘客等级(1/2/3等舱位)\n",
    "# print (train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "\n",
    "# print (train_data[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())\n",
    "# # 将sibsp,parch合并成一个特征，主要是看是否是一个人\n",
    "# train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1 \n",
    "# print (train_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())\n",
    "# train_data['IsAlone'] = 0\n",
    "# train_data.loc[train_data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# print (train_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())\n",
    "# # 终点站这个特征有C，Q，S三个值，这个特征有缺失值，将其填充为S。同样需要进行映射为0,1,2。\n",
    "# train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "# print (train_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n",
    "# # 船票票价这个特征是一个连续型数据，我们对其进行处理平分为四等分，后面分别映射为0，1，2，3。\n",
    "# # raw_data['Fare'] = raw_data['Fare'].fillna(raw_data['Fare'].median())\n",
    "# train_data['CategoricalFare'] = pd.qcut(train_data['Fare'], 4)\n",
    "# print (train_data[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())\n",
    "# # 年龄这个特征同样也是连续型数据，而且缺失值比较多，我们可以将缺失值当做一个类别进行处理，其他的年龄可以等分为五种类别，在后续的数据清理中处理，这里就总共有六种类别\n",
    "# age_null_count = train_data['Age'].isnull().sum()\n",
    "# averge_age = train_data['Age'].sum() / (891-age_null_count)\n",
    "# # 将为空的年龄填成平均年龄\n",
    "# train_data['Age'] = train_data['Age'].fillna(averge_age)\n",
    "# # print(raw_data['Age'])\n",
    "# # print(age_not_null_sum / (891-age_null_count))\n",
    "# # print(raw_data['Survived'][raw_data['Age'].isnull()])\n",
    "# train_data['CategoricalAge'] = pd.cut(train_data['Age'], 5)\n",
    "# print (train_data[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())\n",
    "\n",
    "def processing_data(dataset):\n",
    "# 处理数据\n",
    "#     性别映射为0，1\n",
    "    dataset['Sex'] = dataset['Sex'].replace(['male', 'female'],[0, 1])\n",
    "    \n",
    "    # 将SibSp和Parch两个合并为一个特征，家庭大小，并同时扩展为是否独自一人的特征\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    \n",
    "#     终点站，缺失值补充为S，有三种类型 \n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # 票价，0，1，2，3四种\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # 年龄，缺失值为类别5\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n",
    "    dataset.loc[ dataset['Age'].isnull(), 'Age']                       = 5\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "    #replace missing value with U0\n",
    "    dataset['Cabin'] = dataset.Cabin.fillna('U0') # dataset.Cabin[dataset.Cabin.isnull()]='U0'\n",
    "    \n",
    "    drop_elements = ['PassengerId', 'Name', 'Ticket', 'SibSp','Parch']\n",
    "    dataset = dataset.drop(drop_elements, axis = 1)\n",
    "    \n",
    "    model_data = dataset[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'FamilySize', 'IsAlone']]\n",
    "#     pre_treatment_data = model_data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "    data = model_data.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)), axis=0)\n",
    "\n",
    "    return data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(processing_data(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f389a6a1518>"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f389a6a1ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画图\n",
    "# train_data.groupby(['Sex','Survived'])['Survived'].count()\n",
    "train_data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar()\n",
    "# train_data.groupby(['Pclass','Survived'])['Pclass'].count()\n",
    "# train_data[['Pclass','Survived']].groupby(['Pclass']).mean().plot.bar()\n",
    "\n",
    "bins = [0, 12, 18, 65, 100]\n",
    "train_data['Age_group'] = pd.cut(train_data['Age'], bins)\n",
    "train_data.groupby('Age_group')['Survived'].mean().plot(kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector \n",
    "    n_y -- scalar, number of classes \n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "    X = tf.placeholder(shape=[n_x, None], dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=[n_y, None], dtype=tf.float32)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.Variable(tf.random_normal([7, 4]), name='W1')\n",
    "    b1 = tf.Variable(tf.random_normal([1, 4]), name='b1')\n",
    "\n",
    "    W2 = tf.Variable(tf.random_normal([4, 10]), name='W2')\n",
    "    b2 = tf.Variable(tf.random_normal([1, 10]), name='b2')\n",
    "\n",
    "    W3 = tf.Variable(tf.random_normal([10, 1]), name='W3')\n",
    "    b3 = tf.Variable(tf.random_normal([1, 1]), name='b3')\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(X, W1), b1)                                            # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(A1, W2), b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(A2, W3), b3)                                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "#     print(logits)\n",
    "#     print(labels)\n",
    "\n",
    "    print(Z3.shape)\n",
    "    print(Y.shape)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []       # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X = tf.placeholder(dtype = np.float32, shape = [n_x, m])\n",
    "    Y = tf.placeholder(dtype = np.float32, shape = [n_y, 1])  \n",
    "    print(X.shape[1])\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "#     print(parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            print(minibatch_size)\n",
    "            print(m)\n",
    "            print(m / minibatch_size)\n",
    "        \n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
    "            \n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        print('Total time: {0} seconds'.format(time.time() - start_time))\n",
    "        print('Optimization Finished!')\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: train_set.T, Y: train_label.T}))\n",
    "        print (\"-------------Done----------------------\")\n",
    "\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(891, 1)\n",
      "(891, 1)\n",
      "32\n",
      "7\n",
      "0.21875\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-441-fe7fc82b03d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(train_label.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(data.info())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# print(data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-440-4e21b5296002>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mminibatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_mini_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mminibatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/titanic/tf_utils.py\u001b[0m in \u001b[0;36mrandom_mini_batches\u001b[0;34m(X, Y, mini_batch_size, seed)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Step 1: Shuffle (X, Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mpermutation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mshuffled_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mshuffled_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# preTreatmentData(train_data)\n",
    "# parameters = model(train_data, train_label)\n",
    "data = processing_data(train_data)\n",
    "train_label = train_data['Survived']\n",
    "\n",
    "# print(data.shape)\n",
    "# print(train_label.shape)\n",
    "model(data, train_label)\n",
    "# print(data.info())\n",
    "# print(data.shape)\n",
    "# train_data.info()\n",
    "# print(preTreatmentData(train_data))\n",
    "# print(train_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
